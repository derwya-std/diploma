{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T23:58:16.504632Z",
     "start_time": "2025-06-05T23:58:16.494571Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from model import VIOCNN\n",
    "from dataset import VIOPreprocessedDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = {\n",
    "    \"data_root\": \"./output\",\n",
    "    \"batch_size\": 8,\n",
    "    \"sequence_length\": 8,\n",
    "    \"imu_per_frame\": 50,\n",
    "    \"image_size\": (480, 640),\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"epochs\": 150,\n",
    "    \"train_split\": 0.8,\n",
    "    \"num_workers\": 8,\n",
    "    \"checkpoint_dir\": \"./checkpoints\",\n",
    "    \"resume_training\": True,\n",
    "    \"use_tensorboard\": True,\n",
    "    \"imu_noise_std\": 0.01,\n",
    "    \"imu_dropout_prob\": 0.05,\n",
    "    \"p_invert\": 0.05,\n",
    "    \"p_bgr\": 0.05,\n",
    "    \"p_gray\": 0.05,\n",
    "    \"p_mask\": 0.05,\n",
    "    \"use_quat\": False\n",
    "}\n",
    "\n",
    "os.makedirs(config[\"checkpoint_dir\"], exist_ok=True)\n",
    "if config[\"use_tensorboard\"]:\n",
    "    writer = SummaryWriter(os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
    "\n",
    "def create_csv_from_preprocessed(root):\n",
    "    imu_dir, lbl_dir = os.path.join(root, \"imu\"), os.path.join(root, \"labels\")\n",
    "    ts = np.load(os.path.join(root, \"image_timestamps.npy\"))\n",
    "    imu_out, odo_out = os.path.join(root, \"imu_data.csv\"), os.path.join(root, \"odom_data.csv\")\n",
    "    if not os.path.exists(imu_out):\n",
    "        with open(imu_out, \"w\") as f:\n",
    "            f.write(\"timestamp,ax,ay,az,gx,gy,gz\\n\")\n",
    "            for i, t in enumerate(ts):\n",
    "                data = np.load(os.path.join(imu_dir, f\"imu_{i:06d}.npy\"))\n",
    "                for k, s in enumerate(data[::-1]):\n",
    "                    f.write(f\"{t - k * 1e6},{','.join(map(str, s))}\\n\")\n",
    "    if not os.path.exists(odo_out):\n",
    "        with open(odo_out, \"w\") as f:\n",
    "            f.write(\"timestamp,x,y,z,roll,pitch,yaw\\n\")\n",
    "            for i, t in enumerate(ts):\n",
    "                lbl = np.load(os.path.join(lbl_dir, f\"label_{i:06d}.npy\"))\n",
    "                x, y, z, qx, qy, qz, qw = lbl\n",
    "                q = np.array([qx, qy, qz, qw])\n",
    "                n = np.linalg.norm(q)\n",
    "                if n < 1e-8:\n",
    "                    r = p = yaw = 0\n",
    "                else:\n",
    "                    r, p, yaw = R.from_quat(q / n).as_euler('xyz')\n",
    "                f.write(f\"{t},{x},{y},{z},{r},{p},{yaw}\\n\")\n",
    "\n",
    "def create_datasets(cf):\n",
    "    create_csv_from_preprocessed(cf[\"data_root\"])\n",
    "    ds = VIOPreprocessedDataset(\n",
    "        data_root=cf[\"data_root\"],\n",
    "        imu_csv=os.path.join(cf[\"data_root\"], \"imu_data.csv\"),\n",
    "        odom_csv=os.path.join(cf[\"data_root\"], \"odom_data.csv\"),\n",
    "        sequence_length=cf[\"sequence_length\"],\n",
    "        imu_per_frame=cf[\"imu_per_frame\"],\n",
    "        image_size=cf[\"image_size\"][::-1],\n",
    "        imu_noise_std=cf[\"imu_noise_std\"],\n",
    "        imu_dropout_prob=cf[\"imu_dropout_prob\"],\n",
    "        p_invert=cf[\"p_invert\"],\n",
    "        p_bgr=cf[\"p_bgr\"],\n",
    "        p_gray=cf[\"p_gray\"],\n",
    "        p_mask=cf[\"p_mask\"],\n",
    "    )\n",
    "    n_train = int(cf[\"train_split\"] * len(ds))\n",
    "    return random_split(ds, [n_train, len(ds) - n_train], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T23:58:18.050367Z",
     "start_time": "2025-06-05T23:58:16.521318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_ds, val_ds = create_datasets(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T23:58:19.090357Z",
     "start_time": "2025-06-05T23:58:18.066443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU rows : 1844250\n",
      "Odom rows: 36885\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "imu_df = pd.read_csv(\"./output/imu_data.csv\")\n",
    "odom_df = pd.read_csv(\"./output/odom_data.csv\")\n",
    "print(\"IMU rows :\", len(imu_df))\n",
    "print(\"Odom rows:\", len(odom_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mp.get_start_method(allow_none=True) != \"spawn\":\n",
    "    mp.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mp.get_context(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T23:58:19.112496Z",
     "start_time": "2025-06-05T23:58:19.109658Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds,\n",
    "                          batch_size=config[\"batch_size\"],\n",
    "                          shuffle=True,\n",
    "                          num_workers=config[\"num_workers\"],\n",
    "                          persistent_workers=True,\n",
    "                          multiprocessing_context=ctx,\n",
    "                          pin_memory=True\n",
    "                          )\n",
    "val_loader = DataLoader(val_ds,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=False,\n",
    "                        num_workers=config[\"num_workers\"],\n",
    "                        persistent_workers=True,\n",
    "                        multiprocessing_context=ctx,\n",
    "                        pin_memory=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeodesicLoss(nn.Module):\n",
    "    def forward(self, pred, target):\n",
    "        def rot_mat(r):\n",
    "            theta = torch.linalg.norm(r, dim=-1, keepdim=True).clamp(min=1e-6)\n",
    "            axis  = r / theta\n",
    "            K     = torch.zeros(*r.shape[:-1], 3, 3, device=r.device)\n",
    "            K[..., 0, 1], K[..., 0, 2] = -axis[..., 2],  axis[..., 1]\n",
    "            K[..., 1, 0], K[..., 1, 2] =  axis[..., 2], -axis[..., 0]\n",
    "            K[..., 2, 0], K[..., 2, 1] = -axis[..., 1],  axis[..., 0]\n",
    "            I = torch.eye(3, device=r.device)\n",
    "            return I + torch.sin(theta)[..., None] * K + (1 - torch.cos(theta))[..., None] * (K @ K)\n",
    "\n",
    "        r = pred.view(-1, 3); t = target.view(-1, 3)\n",
    "        R_pred = rot_mat(r); R_gt = rot_mat(t)\n",
    "        R_diff = R_pred @ R_gt.transpose(-1, -2)\n",
    "        trace  = R_diff.diagonal(offset=0, dim1=-2, dim2=-1).sum(-1)\n",
    "        angle  = torch.acos(torch.clamp((trace - 1) / 2, -1+1e-6, 1-1e-6))\n",
    "        return angle.mean()\n",
    "\n",
    "class VIOLoss(nn.Module):\n",
    "    def __init__(self, huber_delta=0.1):\n",
    "        super().__init__()\n",
    "        self.huber = nn.HuberLoss(delta=huber_delta)\n",
    "        self.geo   = GeodesicLoss()\n",
    "    def forward(self, pred, target):\n",
    "        pos_p, rot_p = pred[..., :3], pred[..., 3:]\n",
    "        pos_t, rot_t = target[..., :3], target[..., 3:]\n",
    "        return self.huber(pos_p, pos_t) + 0.5 * self.geo(rot_p, rot_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T23:58:19.456159Z",
     "start_time": "2025-06-05T23:58:19.172886Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VIOCNN(\n",
    "    img_channels=3,\n",
    "    imu_dim=6,\n",
    "    emb_dim=192,\n",
    "    hidden_size=256,\n",
    "    gru_layers=3,\n",
    "    dropout_p=0.2\n",
    ").to(device)\n",
    "criterion = VIOLoss()\n",
    "\n",
    "optimiser = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=config[\"learning_rate\"],\n",
    "                              weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimiser,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=4,\n",
    "    threshold=2e-4,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "patience, min_delta, best_val, pat_cnt = 30, 0.002, float(\"inf\"), 0\n",
    "start_ep, history = 0, {\"loss\": [], \"val_loss\": []}\n",
    "\n",
    "cp = os.path.join(config[\"checkpoint_dir\"], \"latest_checkpoint.pth\")\n",
    "if config[\"resume_training\"] and os.path.exists(cp):\n",
    "    ckpt = torch.load(cp, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    optimiser.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(ckpt[\"scheduler_state_dict\"])\n",
    "    start_ep, best_val = ckpt[\"epoch\"] + 1, ckpt[\"best_val_loss\"]\n",
    "    history = ckpt[\"train_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 3,809,677\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_component_losses(pred, target):\n",
    "    \"\"\"Returns dict with position, rotation and total loss components.\"\"\"\n",
    "    pos_p, rot_p = pred[..., :3], pred[..., 3:]\n",
    "    pos_t, rot_t = target[..., :3], target[..., 3:]\n",
    "\n",
    "    pos_loss = criterion.huber(pos_p, pos_t)          # Huber positional\n",
    "    rot_loss = criterion.geo(rot_p, rot_t)            # Geodesic rotational\n",
    "    total    = pos_loss + 0.5 * rot_loss              # match VIOLoss weighting\n",
    "    return {'pos': pos_loss, 'rot': rot_loss, 'total': total}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, train=True, epoch_idx=0):\n",
    "    model.train() if train else model.eval()\n",
    "    sums = {'pos': 0., 'rot': 0., 'total': 0.}\n",
    "    count = 0\n",
    "\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for imgs, imu, poses, lens in (pbar := tqdm(loader, leave=False)):\n",
    "            imgs, imu, poses = imgs.to(device), imu.to(device), poses.to(device)\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            pred, _   = model(imgs, imu, lens)\n",
    "            losses    = compute_component_losses(pred, poses)\n",
    "\n",
    "            if train:\n",
    "                losses['total'].backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimiser.step()\n",
    "\n",
    "            # accumulate\n",
    "            bs = imgs.size(0)\n",
    "            count += bs\n",
    "            for k in sums:\n",
    "                sums[k] += losses[k].item() * bs\n",
    "\n",
    "            pbar.set_postfix({f\"{k}_loss\": f\"{v.item():.3f}\" for k, v in losses.items()})\n",
    "\n",
    "    # averages\n",
    "    for k in sums:\n",
    "        sums[k] /= count\n",
    "    return sums  # dict of avg losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from math import ceil\n",
    "\n",
    "def map_view_val_batch(model, val_loader, device='cuda', max_seq: int = 9):\n",
    "    \"\"\"Plot up to `max_seq` sequences from one validation batch.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        imgs, imu, gt_poses, seq_lens = next(iter(val_loader))\n",
    "        imgs, imu = imgs.to(device), imu.to(device)\n",
    "        pred_poses, _ = model(imgs, imu, seq_lens)\n",
    "\n",
    "    B = min(len(gt_poses), max_seq)\n",
    "    cols = 3\n",
    "    rows = ceil(B / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4),\n",
    "                             squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx in range(B):\n",
    "        ax = axes[idx]\n",
    "        gt = gt_poses[idx, :, :2].cpu().numpy()\n",
    "        pr = pred_poses[idx, :, :2].cpu().numpy()\n",
    "\n",
    "        # cumulative positions\n",
    "        gt_xy   = np.vstack([[0, 0], np.cumsum(gt, 0)])\n",
    "        pred_xy = np.vstack([[0, 0], np.cumsum(pr, 0)])\n",
    "\n",
    "        rmse = np.sqrt(((gt_xy - pred_xy) ** 2).sum(1).mean())\n",
    "\n",
    "        ax.plot(gt_xy[:, 0],   gt_xy[:, 1],  'o-',  lw=2,  label='GT')\n",
    "        ax.plot(pred_xy[:, 0], pred_xy[:, 1], 'x--', lw=1.5, label='Pred')\n",
    "        ax.scatter(gt_xy[0, 0],  gt_xy[0, 1],  c='green', marker='s', s=60)\n",
    "        ax.scatter(gt_xy[-1,0],  gt_xy[-1, 1],  c='red',   marker='*', s=80)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.grid(True, ls=':')\n",
    "        ax.set_title(f'seq {idx}  |  XY-RMSE: {rmse:.2f} m')\n",
    "        ax.set_xlabel('X (m)'); ax.set_ylabel('Y (m)')\n",
    "        ax.legend(frameon=False, fontsize=8)\n",
    "\n",
    "    # hide unused axes\n",
    "    for j in range(B, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-05T23:58:19.916905Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e301dfba7e46c78960d5d136ecfd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3688 [00:19<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdd7a1b9c3540009399dac2cf362e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/922 [00:20<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/150 | 1233.2s | train tot 0.0394 (pos 0.0251, rot 0.0286) | val tot 0.0402 (pos 0.0254, rot 0.0295) | lr 5.00e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3440bd724be413ea31bf18f0bc11330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ep in range(start_ep, config[\"epochs\"]):\n",
    "    t0 = time.time()\n",
    "    tr = run_epoch(train_loader, True,  ep)\n",
    "    vl = run_epoch(val_loader,   False, ep)\n",
    "    \n",
    "    scheduler.step(vl['total'])\n",
    "\n",
    "    history['loss'].append(tr['total'])\n",
    "    history['val_loss'].append(vl['total'])\n",
    "\n",
    "    if config['use_tensorboard']:\n",
    "        writer.add_scalars(\"Loss/train\", tr, ep)\n",
    "        writer.add_scalars(\"Loss/val\",   vl, ep)\n",
    "        writer.add_scalar(\"LR\", optimiser.param_groups[0]['lr'], ep)\n",
    "\n",
    "    print(f\"Epoch {ep+1:02d}/{config['epochs']} | {time.time()-t0:.1f}s \"\n",
    "          f\"| train tot {tr['total']:.4f} (pos {tr['pos']:.4f}, rot {tr['rot']:.4f}) \"\n",
    "          f\"| val tot {vl['total']:.4f} (pos {vl['pos']:.4f}, rot {vl['rot']:.4f}) \"\n",
    "          f\"| lr {optimiser.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    ck = {\n",
    "        \"epoch\": ep,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimiser.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"train_history\": history,\n",
    "        \"best_val_loss\": best_val,\n",
    "        \"config\": config\n",
    "    }\n",
    "    torch.save(ck, cp)\n",
    "\n",
    "    if vl['total'] < best_val * (1 - min_delta):\n",
    "        best_val, pat_cnt = vl['total'], 0\n",
    "        torch.save(ck, os.path.join(config[\"checkpoint_dir\"], \"best_checkpoint.pth\"))\n",
    "    else:\n",
    "        pat_cnt += 1\n",
    "        if pat_cnt >= patience:\n",
    "            print(f\"Early stop at epoch {ep+1}\")\n",
    "            break\n",
    "\n",
    "if config['use_tensorboard']:\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_view_val_batch(model, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
